import os
import re
import time
import json
from typing import Dict, List, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

import pandas as pd
from openai import OpenAI


# ===== Qwen API é…ç½® =====
ROOT_DIR = ""  # æ•°æ®é›†è·¯å¾„
OUTPUT_FILE = ""  # å½“å‰ç›®å½•ä¸‹ä¿å­˜ç»“æœ
QWEN_API_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"
QWEN_API_KEY = ""
MODEL = "qwen3-235b-a22b-thinking-2507"  # Qwen3 235B æ¨¡å‹ 

# å¹¶å‘é…ç½®
MAX_WORKERS = 1    

# éœ€è¦åˆ†æçš„æ–‡ä»¶æ‰©å±•å
ALLOWED_EXTS = [".sol"]

# æ–‡ä»¶é€‰æ‹©æ§åˆ¶ï¼ˆ0 è¡¨ç¤ºä¸é™ï¼‰
MAX_FILES = 0              # å…¨å±€æœ€å¤šå¤„ç†çš„æ–‡ä»¶æ•°
SKIP_FILES = 0            # è·³è¿‡å‰ N ä¸ª
MAX_FILES_PER_CLASS = 0    # æ¯ä¸ªæ¼æ´ç±»åˆ«æœ€å¤šå¤„ç†çš„æ–‡ä»¶æ•°
# ===========================


class VulnerabilityAnalyzer:
    """æ¼æ´åˆ†æå™¨ - Qwen API ç‰ˆæœ¬

    é€šè¿‡ HTTP è°ƒç”¨ Qwen API æœåŠ¡ï¼Œå¯¹è¾“å…¥çš„æ™ºèƒ½åˆçº¦æ–‡æœ¬è¿›è¡Œä¹ç±»æ¼æ´çš„äºŒåˆ†ç±»åˆ¤å®šã€‚

    å‚æ•°è¯´æ˜ï¼š
    - api_url: Qwen API åœ°å€
    - api_key: API å¯†é’¥
    - model_name: æ¨¡å‹åç§°
    - temperature: é‡‡æ ·æ¸©åº¦ï¼ˆè¶Šä½è¶Šç¡®å®šï¼Œè¶Šé«˜è¶Šå‘æ•£ï¼‰
    - max_tokens: æœ€å¤§è¾“å‡ºtokenæ•°
    - request_timeout/request_retries: HTTP è¶…æ—¶ä¸é‡è¯•è®¾ç½®
    - max_workers: å¹¶å‘çº¿ç¨‹æ•°
    """
    def __init__(
        self,
        api_url: Optional[str] = None,
        api_key: Optional[str] = None,
        model_name: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: int = 65536,
        request_timeout: int = 120,
        request_retries: int = 3,
        max_workers: int = 1,
    ):
        self.api_url = api_url or os.environ.get("QWEN_API_URL", QWEN_API_URL)
        self.api_key = api_key or os.environ.get("QWEN_API_KEY", QWEN_API_KEY)
        self.model_name = model_name or os.environ.get("QWEN_MODEL", MODEL)
        self.temperature = float(temperature)
        self.max_tokens = int(max_tokens)
        self.request_timeout = int(request_timeout)
        self.request_retries = int(request_retries)
        self.max_workers = max(1, int(max_workers))

        # ä½¿ç”¨å®˜æ–¹æ¨èçš„ OpenAI SDK
        self.client = OpenAI(
            api_key=self.api_key,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
        )

        self.vulnerability_types = [
            "Reentrancy",
            "Access Control",
            "Arithmetic Issues",
            "Unchecked Return Values For Low Level Calls",
            "Denial of Service",
            "Bad Randomness",
            "Front-Running",
            "Time manipulation",
            "Short Address Attack",
        ]

        # ä¸¥æ ¼éµå¾ª"æ¼æ´å: 0/1"è¾“å‡ºé£æ ¼ï¼ˆæ–‡æ¡£è¾“å…¥é£æ ¼ï¼‰
        self.system_prompt = (
            "You are a semantic analyzer of text. Here are nine common vulnerabilities.\n"
            "1. Reentrancy\n"
            "also known as or related to race to empty, recursive call vulnerability, call to the unknown\n"
            "2. Access Control\n"
            "3. Arithmetic Issues\n"
            "also known as integer overflow and integer underflow\n"
            "4. Unchecked Return Values For Low Level Calls\n"
            "also known as or related to silent failing sends, unchecked-send\n"
            "5. Denial of Service\n"
            "including gas limit reached, unexpected throw, unexpected kill, access control breached\n"
            "6. Bad Randomness\n"
            "also known as nothing is secret\n"
            "7. Front-Running\n"
            "also known as time-of-check vs time-of-use (TOCTOU), race condition, transaction ordering dependence (TOD)\n"
            "8. Time manipulation\n"
            "also known as timestamp dependence\n"
            "9. Short Address Attack\n"
            "also known as or related to off-chain issues, client vulnerabilities.\n\n"
            "Provide a detailed analysis with explanations, then MUST end your response with a summary in this EXACT format:\n\n"
            "Reentrancy: 0\n"
            "Access Control: 0\n"
            "Arithmetic Issues: 0\n"
            "Unchecked Return Values For Low Level Calls: 0\n"
            "Denial of Service: 0\n"
            "Bad Randomness: 0\n"
            "Front-Running: 0\n"
            "Time manipulation: 0\n"
            "Short Address Attack: 0\n\n"
            "The following text is a vulnerability detection result for a smart contract. Use 0 or 1 to indicate whether there are specific types of vulnerabilities. For example: \"Reentrancy: 1\". Think step by step, carefully."
        )

    # ---------- Helpers ----------

    def _ensure_int_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """ç¡®ä¿è¾“å‡º DataFrame ä¸­ä¸è®¡æ•°ç›¸å…³çš„åˆ—ä¸ºæ•´å‹ï¼Œæ—¶é—´åˆ—ä¸ºæµ®ç‚¹å‹ã€‚

        è¯´æ˜ï¼šExcel è¯»å†™åå¯èƒ½å‡ºç°ç±»å‹æ¼‚ç§»ï¼Œè¿™é‡Œåšä¸€æ¬¡ç»Ÿä¸€è½¬æ¢ï¼Œé¿å…åç»­å¤„ç†æ—¶æŠ¥é”™ã€‚
        """
        # åªå¤„ç†æ¼æ´ç±»å‹åˆ—ä¸ºæ•´å‹
        int_cols = self.vulnerability_types
        for c in int_cols:
            if c in df.columns:
                df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0).astype(int)
        
        # ç¡®ä¿èŠ±è´¹æ—¶é—´åˆ—ä¸ºæµ®ç‚¹å‹
        if "èŠ±è´¹æ—¶é—´" in df.columns:
            df["èŠ±è´¹æ—¶é—´"] = pd.to_numeric(df["èŠ±è´¹æ—¶é—´"], errors="coerce").fillna(0.0).astype(float)
        
        return df

    def _read_file_text(self, path: str) -> str:
        """ä»¥å¤šç¼–ç å°è¯•è¯»å–æ–‡æœ¬ï¼Œé¿å…ç¼–ç ä¸å…¼å®¹å¯¼è‡´å¤±è´¥ã€‚"""
        for enc in ("utf-8", "utf-8-sig", "gb18030", "latin-1"):
            try:
                with open(path, "r", encoding=enc, errors="ignore") as f:
                    return f.read()
            except Exception:
                continue
        return ""

    def _normalize_label(self, name: str) -> str:
        """å°†ç›®å½•åï¼ˆå¯èƒ½å¤§å°å†™/åˆ†éš”ç¬¦ä¸åŒï¼‰è§„èŒƒåŒ–ä¸ºæ ‡å‡†æ¼æ´åã€‚"""
        name = (name or "").strip()
        for t in self.vulnerability_types:
            if name.lower() == t.lower():
                return t
        aliases = {
            "reentrancy": "Reentrancy",
            "accesscontrol": "Access Control",
            "arithmetic": "Arithmetic Issues",
            "uncheckedlowlevelcalls": "Unchecked Return Values For Low Level Calls",
            "denialofservice": "Denial of Service",
            "badrandomness": "Bad Randomness",
            "frontrunning": "Front-Running",
            "timemanipulation": "Time manipulation",
            "shortaddresses": "Short Address Attack",
        }
        import re as _re
        key = _re.sub(r"[\s_-]+", "", name.lower())
        return aliases.get(key, "")

    # ---------- Qwen API ----------

    def call_qwen_api(self, contract_content: str) -> Tuple[str, str]:
        """è°ƒç”¨ Qwen APIï¼Œä½¿ç”¨å®˜æ–¹æ¨èçš„ OpenAI SDKã€‚
        
        è¿”å›: (response_content, reasoning_content)
        """
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": f"Please analyze the following smart contract code:\n\n{contract_content}"}
        ]

        for attempt in range(1, self.request_retries + 1):
            try:
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=messages,
                    temperature=self.temperature,
                    max_tokens=self.max_tokens,
                    stream=False
                )
                
                response_content = response.choices[0].message.content
                reasoning_content = getattr(response.choices[0].message, 'reasoning_content', '')
                
                # è¾“å‡ºAIçš„å›ç­”
                if response_content:
                    print("=" * 60)
                    print("ğŸ¤– AIåˆ†æç»“æœ:")
                    print("=" * 60)
                    print(response_content)
                    print("=" * 60)
                elif reasoning_content:
                    print("=" * 60)
                    print("ğŸ¤– AIæ€è€ƒè¿‡ç¨‹:")
                    print("=" * 60)
                    print(reasoning_content[-2000:])  # æ˜¾ç¤ºæœ€å2000å­—ç¬¦
                    print("=" * 60)
                    # å°è¯•ä»æ€è€ƒè¿‡ç¨‹ä¸­æå–
                    response_content = self._extract_from_reasoning(reasoning_content)
                    if response_content:
                        print("ğŸ“ æå–çš„åˆ†æç»“æœ:")
                        print(response_content)
                        print("=" * 60)
                
                return response_content if response_content else "", reasoning_content
                    
            except Exception as e:
                if attempt < self.request_retries:
                    wait = min(2**attempt, 8)
                    print(f"è°ƒç”¨Qwen APIå¤±è´¥(ç¬¬ {attempt}/{self.request_retries} æ¬¡)ï¼Œé‡è¯•å‰ç­‰å¾… {wait}sï¼š{e}")
                    time.sleep(wait)
                else:
                    print(f"è°ƒç”¨Qwen APIå¤±è´¥(æœ€ç»ˆå¤±è´¥)ï¼š{e}")
                    
        return "", ""

    def _extract_from_reasoning(self, reasoning_content: str) -> str:
        """ä»AIçš„æ€è€ƒè¿‡ç¨‹ä¸­æå–æœ€ç»ˆç­”æ¡ˆ"""
        if not reasoning_content:
            return ""
        
        # å°è¯•ä»æ€è€ƒè¿‡ç¨‹ä¸­æå–æœ€ç»ˆçš„æ¼æ´åˆ†æç»“æœ
        lines = reasoning_content.split('\n')
        for line in reversed(lines):  # ä»åå¾€å‰æ‰¾ï¼Œé€šå¸¸ç»“æœåœ¨æœ€å
            line = line.strip()
            if any(vuln in line for vuln in self.vulnerability_types):
                return line
        return reasoning_content

    def parse_vulnerability_response(self, response: str) -> Dict[str, int]:
        """ä»æ¨¡å‹æ–‡æœ¬è¾“å‡ºä¸­è§£æä¹ç±»æ¼æ´çš„ 0/1 ç»“æœã€‚

        è§£æç­–ç•¥ï¼šå¯¹æ¯ä¸€ç±»æ¼æ´å°è¯•å¤šç§åˆ†éš”ç¬¦åŒ¹é…ï¼ˆ:ã€=ã€ç©ºæ ¼ï¼‰ï¼Œæœªå‘½ä¸­é»˜è®¤ 0ã€‚
        """
        # æŒ‰"æ¼æ´å: 0/1"è§£æï¼›é»˜è®¤ 0
        results = {k: 0 for k in self.vulnerability_types}
        if not response:
            return results

        text = response
        found_any = False
        
        for vuln_type in self.vulnerability_types:
            # åŒ¹é…å¤šç§æ ¼å¼çš„æ¼æ´è¾“å‡º
            patterns = [
                # æ ‡å‡†æ ¼å¼: "Reentrancy: 0" æˆ– "**Reentrancy**: 0"
                rf"\*\*{re.escape(vuln_type)}\*\*\s*:\s*([01])\b",
                rf"{re.escape(vuln_type)}\s*:\s*([01])\b",
                rf"{re.escape(vuln_type)}\s*=\s*([01])\b",
                rf"{re.escape(vuln_type)}\s+([01])\b",
                # ç¼–å·æ ¼å¼: "1. **Reentrancy**: 0"
                rf"\d+\.\s*\*\*{re.escape(vuln_type)}\*\*\s*:\s*([01])\b",
                rf"\d+\.\s*{re.escape(vuln_type)}\s*[:=]\s*([01])\b",
                # å¤§å°å†™ä¸æ•æ„Ÿ
                rf"(?i)\*\*{re.escape(vuln_type.lower())}\*\*\s*:\s*([01])\b",
                rf"(?i){re.escape(vuln_type.lower())}\s*[:=]\s*([01])\b",
                # æ›´çµæ´»çš„åŒ¹é…
                rf"{re.escape(vuln_type)}\s*[-:=]\s*([01])\b",
            ]
            for pat in patterns:
                m = re.search(pat, text, re.IGNORECASE)
                if m:
                    try:
                        results[vuln_type] = int(m.group(1))
                        found_any = True
                        print(f"âœ… è§£æåˆ°: {vuln_type} = {results[vuln_type]}")
                    except Exception:
                        results[vuln_type] = 0
                    break

        return results

    def compute_results_metric(self, df_output: pd.DataFrame) -> pd.DataFrame:
        """åŸºäºç»“æœè¡¨è®¡ç®—æ¯ç±» TP/FP/TN/FNï¼Œä½œä¸ºæŒ‡æ ‡è¡¨ã€‚

        è§„åˆ™ï¼šå¯¹æ¯ä¸ªåˆ†æè®°å½•ä¸æ¯ä¸ªæ¼æ´ï¼š
        - æ¯è¡Œè®°å½•ä»£è¡¨ä¸€æ¬¡åˆ†æç»“æœï¼ˆ0æˆ–1ï¼‰
        - è‹¥å®é™…æ ‡ç­¾ä¸ºè¯¥æ¼æ´ä¸”é¢„æµ‹ä¸º1ï¼šTP += 1
        - è‹¥å®é™…æ ‡ç­¾ä¸ºè¯¥æ¼æ´ä¸”é¢„æµ‹ä¸º0ï¼šFN += 1
        - è‹¥å®é™…æ ‡ç­¾ä¸ä¸ºè¯¥æ¼æ´ä¸”é¢„æµ‹ä¸º1ï¼šFP += 1
        - è‹¥å®é™…æ ‡ç­¾ä¸ä¸ºè¯¥æ¼æ´ä¸”é¢„æµ‹ä¸º0ï¼šTN += 1
        """
        if df_output is None or df_output.empty:
            return pd.DataFrame(columns=["æ¼æ´ç±»å‹", "TP", "FP", "TN", "FN"])

        df = self._ensure_int_columns(df_output.copy())

        counts: Dict[str, Dict[str, int]] = {
            v: {"TP": 0, "FP": 0, "TN": 0, "FN": 0} for v in self.vulnerability_types
        }

        for _, row in df.iterrows():
            actual_label = str(row.get("å®é™…æ¼æ´ç±»å‹", ""))
            for vuln in self.vulnerability_types:
                predicted = int(pd.to_numeric(row.get(vuln, 0), errors="coerce"))
                if predicted < 0:
                    predicted = 0
                
                if actual_label == vuln:
                    if predicted == 1:
                        counts[vuln]["TP"] += 1
                    else:
                        counts[vuln]["FN"] += 1
                else:
                    if predicted == 1:
                        counts[vuln]["FP"] += 1
                    else:
                        counts[vuln]["TN"] += 1

        data = []
        for vuln in self.vulnerability_types:
            c = counts[vuln]
            data.append({
                "æ¼æ´ç±»å‹": vuln,
                "TP": c["TP"],
                "FP": c["FP"],
                "TN": c["TN"],
                "FN": c["FN"],
            })
        df = pd.DataFrame(data)

        # è®¡ç®— Precision / Recall / Specificity / F1ï¼ˆåˆ†æ¯ä¸º 0 æ—¶è®°ä¸º 0.0ï¼‰
        def safe_div(n: float, d: float) -> float:
            try:
                return float(n) / float(d) if float(d) != 0.0 else 0.0
            except Exception:
                return 0.0

        df["Precision"] = df.apply(lambda r: safe_div(r["TP"], r["TP"] + r["FP"]), axis=1)
        df["Recall"] = df.apply(lambda r: safe_div(r["TP"], r["TP"] + r["FN"]), axis=1)
        df["Specificity"] = df.apply(lambda r: safe_div(r["TN"], r["TN"] + r["FP"]), axis=1)
        df["F1"] = df.apply(lambda r: safe_div(2 * r["Precision"] * r["Recall"], r["Precision"] + r["Recall"]), axis=1)

        return df

    def analyze_single_contract(self, contract_content: str) -> Tuple[Dict[str, int], str]:
        """å¯¹å•ä¸ªåˆçº¦æ–‡æœ¬è¿›è¡Œä¸€æ¬¡åˆ†æï¼Œè¿”å›ä¹ç±»æ¼æ´çš„ 0/1 ç»“æœå’ŒAIæ€è€ƒå†…å®¹ã€‚"""
        resp, reasoning = self.call_qwen_api(contract_content)
        if not resp:
            return {k: 0 for k in self.vulnerability_types}, reasoning
        return self.parse_vulnerability_response(resp), reasoning

    # ---------- Folder mode ----------

    def _gather_files(self, root_dir: str, allowed_exts: Tuple[str, ...]) -> List[Tuple[str, str, str]]:
        """éå†æ ¹ç›®å½•ï¼ŒæŒ‰å­ç›®å½•åæ˜ å°„æ¼æ´æ ‡ç­¾ï¼Œæ”¶é›†åˆè§„æ‰©å±•åçš„æ–‡ä»¶åˆ—è¡¨ã€‚"""
        items = []
        root_dir = os.path.abspath(root_dir)
        for dirpath, _, filenames in os.walk(root_dir):
            vuln_label_raw = os.path.basename(dirpath)
            norm_label = self._normalize_label(vuln_label_raw)
            if dirpath == root_dir or not norm_label:
                continue

            for fn in filenames:
                if allowed_exts and not fn.lower().endswith(allowed_exts):
                    continue
                file_path = os.path.join(dirpath, fn)
                rel_id = os.path.relpath(file_path, root_dir).replace("\\", "/")
                items.append((rel_id, file_path, norm_label))
        return items

    def _analyze_one_file(self, rel_id: str, file_path: str, norm_label: str) -> Optional[Dict[str, any]]:
        """è¯»å–æ–‡ä»¶å†…å®¹å¹¶è°ƒç”¨æ¨¡å‹åˆ†æï¼Œè¿”å›å•è¡Œç»“æœè®°å½•ã€‚"""
        content = self._read_file_text(file_path)
        if not content.strip():
            print(f"ç©ºæ–‡ä»¶ï¼Œè·³è¿‡: {rel_id}")
            return None
        
        # è®°å½•åˆ†æå¼€å§‹æ—¶é—´
        start_time = time.time()
        vuln_results, ai_reasoning = self.analyze_single_contract(content)
        # è®¡ç®—èŠ±è´¹æ—¶é—´ï¼ˆç§’ï¼‰
        analysis_time = time.time() - start_time
        
        row = {
            "æ–‡ä»¶ID": rel_id,
            "å®é™…æ¼æ´ç±»å‹": norm_label,
            "èŠ±è´¹æ—¶é—´": round(analysis_time, 2),  # ä¿ç•™2ä½å°æ•°
            "AIæ€è€ƒå†…å®¹": ai_reasoning,  # æ–°å¢AIæ€è€ƒå†…å®¹åˆ—
            #"AIæ€è€ƒå†…å®¹": "",  # ä¸´æ—¶è®¾ç½®ä¸ºç©ºï¼Œä¸æ˜¾ç¤ºAIæ€è€ƒå†…å®¹
            **{k: int(vuln_results.get(k, 0)) for k in self.vulnerability_types},
        }
        print(f"å®Œæˆ: {rel_id} (è€—æ—¶: {analysis_time:.2f}s)")
        return row

    def process_folder(
        self,
        root_dir: str,
        output_file: str,
        allowed_exts: Optional[List[str]] = None,
        max_files: Optional[int] = None,
        skip_files: int = 0,
        max_files_per_class: Optional[int] = None,
    ):
        """ç›®å½•æ¨¡å¼ä¸»æµç¨‹ï¼šæ”¶é›†ã€åˆ†æå¹¶å°†ç»“æœå†™å…¥ Excelã€‚

        é‡è¦è¯´æ˜ï¼š
        - æ¯æ¬¡åˆ†æéƒ½ä¼šä½œä¸ºæ–°çš„ä¸€è¡Œè®°å½•ï¼Œä¸ä¼šç´¯åŠ ç›¸åŒæ–‡ä»¶IDçš„ç»“æœ
        - `MAX_WORKERS`>1 æ—¶ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘è¯·æ±‚ï¼Œä»¥æå‡ API è°ƒç”¨æ•ˆç‡
        """
        if not os.path.isdir(root_dir):
            print(f"ç›®å½•ä¸å­˜åœ¨: {root_dir}")
            return

        if not allowed_exts:
            allowed_exts = [".sol"]
        allowed_exts_t = tuple(x.lower() for x in allowed_exts)

        output_columns = [
            "æ–‡ä»¶ID",
            "å®é™…æ¼æ´ç±»å‹",
            "èŠ±è´¹æ—¶é—´",
            "AIæ€è€ƒå†…å®¹",
            "Reentrancy",
            "Access Control",
            "Arithmetic Issues",
            "Unchecked Return Values For Low Level Calls",
            "Denial of Service",
            "Bad Randomness",
            "Front-Running",
            "Time manipulation",
            "Short Address Attack",
        ]

        df_output = pd.DataFrame(columns=output_columns)
        if os.path.exists(output_file):
            try:
                existing_df = pd.read_excel(output_file, engine="openpyxl")
                if all(col in existing_df.columns for col in output_columns):
                    df_output = existing_df
                    print(f"è¯»å–ç°æœ‰è¾“å‡ºæ–‡ä»¶ï¼Œå·²æœ‰ {len(df_output)} è¡Œæ•°æ®")
                else:
                    print("ç°æœ‰è¾“å‡ºæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
            except Exception as e:
                print(f"è¯»å–è¾“å‡ºæ–‡ä»¶æ—¶å‡ºé”™ï¼Œåˆ›å»ºæ–°æ–‡ä»¶: {e}")

        items = self._gather_files(root_dir, allowed_exts_t)
        if not items:
            print("æœªå‘ç°å¯å¤„ç†çš„æ–‡ä»¶")
            return

        # -------- æ–‡ä»¶æ•°é‡æ§åˆ¶ --------
        if max_files_per_class and max_files_per_class > 0:
            grouped = {}
            for rel_id, file_path, label in items:
                grouped.setdefault(label, []).append((rel_id, file_path, label))
            items_limited = []
            for label, lst in grouped.items():
                items_limited.extend(lst[:max_files_per_class])
            items = items_limited

        if skip_files and skip_files > 0:
            items = items[skip_files:]
        if max_files and max_files > 0:
            items = items[:max_files]

        print(f"å°†å¤„ç† {len(items)} ä¸ªæ–‡ä»¶"
              + (f"ï¼ˆæ¯ç±»ä¸Šé™ {max_files_per_class}ï¼‰" if max_files_per_class else "")
              )

        print(f"å¼€å§‹åˆ†æ...")

        results = []
        if self.max_workers > 1:
            with ThreadPoolExecutor(max_workers=self.max_workers) as ex:
                futs = [ex.submit(self._analyze_one_file, rel_id, file_path, norm_label)
                        for rel_id, file_path, norm_label in items]
                for fut in as_completed(futs):
                    r = fut.result()
                    if r:
                        results.append(r)
        else:
            for rel_id, file_path, norm_label in items:
                r = self._analyze_one_file(rel_id, file_path, norm_label)
                if r:
                    results.append(r)

        # æ¯æ¬¡åˆ†æéƒ½ä½œä¸ºæ–°çš„ä¸€è¡Œæ·»åŠ 
        if results:
            # åˆ›å»ºæ–°çš„DataFrameåŒ…å«æ‰€æœ‰ç»“æœ
            new_df = pd.DataFrame(results)
            # å¦‚æœç°æœ‰æ•°æ®ä¸ºç©ºï¼Œç›´æ¥ä½¿ç”¨æ–°æ•°æ®ï¼›å¦åˆ™è¿æ¥
            if df_output.empty:
                df_output = new_df
            else:
                df_output = pd.concat([df_output, new_df], ignore_index=True)

        # å°†å½“å‰æ‰¹æ¬¡çš„ç»“æœä¿å­˜/æ›´æ–°åˆ°ç»“æœè¡¨
        df_output = self._ensure_int_columns(df_output)
        
        # æŒ‰æ¼æ´ç±»å‹å’Œæ–‡ä»¶IDæ’åºï¼Œä¼˜å…ˆæŒ‰æ¼æ´ç±»å‹é›†ä¸­ï¼ŒåæŒ‰æ–‡ä»¶IDé›†ä¸­
        if not df_output.empty and "æ–‡ä»¶ID" in df_output.columns and "å®é™…æ¼æ´ç±»å‹" in df_output.columns:
            df_output = df_output.sort_values(by=["å®é™…æ¼æ´ç±»å‹", "æ–‡ä»¶ID"], ascending=[True, True]).reset_index(drop=True)
        
        try:
            with pd.ExcelWriter(output_file, engine="openpyxl", mode="w") as writer:
                df_output.to_excel(writer, index=False)
            print(f"\nç›®å½•æ¨¡å¼å®Œæˆï¼å…±å¤„ç† {len(results)} ä¸ªæ–‡ä»¶ï¼Œç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        except Exception as e:
            print(f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")

        # ä»…è¾“å‡ºï¼šç´¯è®¡ï¼ˆæŒ‰æ¬¡æ•°é‡ç®—ï¼‰çš„æŒ‡æ ‡è¡¨åˆ°ä¸€å¼  Excel
        try:
            base = os.path.splitext(output_file)[0]
            metrics_path = base + "_metrics.xlsx"  # è¾“å‡ºä¸º results_metrics.xlsx

            metrics_df = self.compute_results_metric(df_output)
            with pd.ExcelWriter(metrics_path, engine="openpyxl", mode="w") as writer:
                metrics_df.to_excel(writer, index=False)

            print(f"æŒ‡æ ‡è¡¨(ç´¯è®¡ï¼ŒæŒ‰æ¬¡æ•°)å·²ä¿å­˜åˆ°: {metrics_path}")
        except Exception as e:
            print(f"ä¿å­˜æ··æ·†çŸ©é˜µæ—¶å‡ºé”™: {e}")


def main():
    """ç¨‹åºå…¥å£ï¼šæ„é€ åˆ†æå™¨å¹¶æŒ‰é…ç½®è¿è¡Œç›®å½•æ¨¡å¼ã€‚"""
    analyzer = VulnerabilityAnalyzer(
        api_url=QWEN_API_URL,
        api_key=QWEN_API_KEY,
        model_name=MODEL,
        max_workers=MAX_WORKERS,
    )

    if not os.path.isdir(ROOT_DIR):
        print(f"é”™è¯¯ï¼šæ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {ROOT_DIR}")
        print("è¯·ç¡®ä¿æ•°æ®é›†å·²æ­£ç¡®æ”¾ç½®åœ¨æŒ‡å®šç›®å½•ä¸‹")
        return

    analyzer.process_folder(
        root_dir=ROOT_DIR,
        output_file=OUTPUT_FILE,
        allowed_exts=ALLOWED_EXTS,
        max_files=MAX_FILES,
        skip_files=SKIP_FILES,
        max_files_per_class=MAX_FILES_PER_CLASS,
    )


if __name__ == "__main__":
    main()
